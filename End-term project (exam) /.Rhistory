results <- cbind(Pt, Vt, Pt < Vt)
results <- as.data.frame(results)
names(results) <- c('Price', 'Value', 'IfBuy')
rownames(results) <- seq(100,200,10)
results
Pt <- 40000 * exp(-seq(100,200,10)/7)
results <- cbind(Pt, Vt, Pt < Vt)
results <- as.data.frame(results)
names(results) <- c('P(t)', 'V(t)', 'P(t) < V(t)')
rownames(results) <- seq(100,200,10)
results
stargazer(results, title="A Handsome Table", header=T)
?stargazer
install.packages("stargazer")
library(stargazer)
knitr::opts_chunk$set(cache=TRUE,
message=FALSE, warning=FALSE,
fig.path='figs/',
cache.path = '_cache/',
fig.process = function(x) {
x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
if (file.rename(x, x2)) x2 else x
})
library(copula)
library(WVPlots)
library(gridExtra)
library(tidyverse)
library(stargazer)
Pt <- 40000 * exp(-seq(100,200,10)/7)
results <- cbind(Pt, Vt, Pt < Vt)
results <- as.data.frame(results)
names(results) <- c('P(t)', 'V(t)', 'P(t) < V(t)')
rownames(results) <- seq(100,200,10)
results
stargazer(results, title="A Handsome Table", header=T)
Pt <- 40000 * exp(-seq(100,200,10)/7)
results <- cbind(Pt, Vt, Pt < Vt)
results <- as.data.frame(results)
names(results) <- c('P(t)', 'V(t)', 'P(t) < V(t)')
rownames(results) <- seq(100,200,10)
results
stargazer(results, title="A Handsome Table", header=T)
plot(rownames(results) )
plot(results, type='b')
results
plot(results[,2], type='b')
plot(results[,'V(t)'], type='b')
plot(seq(100,200,10), results[,'V(t)'], type='b')
plot(seq(100,200,10), results[,2], type='b', ylab = 'V(t))
''
''
plot(seq(100,200,10), results[,2], type='b', ylab = 'V(t)')
plot(seq(100,200,10), results[,2], type='b', xlab = 't', ylab = 'V(t)')
V
t(V(t))
t(V)
View(V)
plot(V)
Vt_std <- colSds(V)
apply(V, 2, sd)
Vt_sd <- apply(V, 2, sd)
Vt_sd
names(Vt_sd)
names(Vt_sd) <- c(1,2)
Vt_sd
names(Vt_sd) <- seq(100,200,10)
Vt_sd
Vt_sd
t(Vt_sd)
stargazer(t(Vt_sd))
Vt
Vt_sd
data.frame(t=seq(100,200,10), Vt_sd=Vt_sd)
stargazer(data.frame(t=seq(100,200,10), Vt_sd=Vt_sd), title="Standard Deviation of P(t)", header=T)
k <- length(data$ID) # number of data points for each simulation run
B <- 10^5 # number of simulation runs
### simulated k*B data points to save time
simulated_data <- rmycopula(k*B, est$est1[1], est$est1[2], est$est2[1], est$est2[2], est$est3)
V <- c()
for (i in 1:B){
temp_data <- simulated_data[(k*(i-1)+1):(k*i),] # simulated data for current run
total_claim <- rowSums(temp_data)
### calculate V(t) for t=100,110,â€¦,200
V_new <- sapply(seq(100,200,10), function(t) sum(total_claim[total_claim > t]))
V <- rbind(V,V_new)
}
Vt <- colMeans(V) # mean
Vt_sd <- apply(V, 2, sd) #sd
save(Vt, Vt_sd, file = 'Vt.RData')
rm(V)
load('Vt.RData')
Pt <- 40000 * exp(-seq(100,200,10)/7)
results <- cbind(Pt, Vt, Pt < Vt)
results <- as.data.frame(results)
names(results) <- c('P(t)', 'V(t)', 'P(t) < V(t)')
rownames(results) <- seq(100,200,10)
stargazer(results, title="P(t) and V(t)", header=T)
```S
Pt <- 40000 * exp(-seq(100,200,10)/7)
results <- cbind(Pt, Vt, Pt < Vt)
results <- as.data.frame(results)
names(results) <- c('P(t)', 'V(t)', 'P(t) < V(t)')
rownames(results) <- seq(100,200,10)
stargazer(results, title="P(t) and V(t)", header=T)
results
Pt <- 40000 * exp(-seq(100,200,10)/7)
results <- cbind(Pt, Vt, Pt < Vt)
results <- as.data.frame(results)
names(results) <- c('P(t)', 'V(t)', 'P(t) < V(t)')
rownames(results) <- seq(100,200,10)
stargazer(results, title="P(t) and V(t)", header=T)
plot(seq(100,200,10), results[,2], type='b', xlab = 't', ylab = 'V(t)')
stargazer(data.frame(t=seq(100,200,10), Vt_sd=Vt_sd), title="Standard Deviation of P(t)", header=T)
Vt_sd
results
### new parameters est2 for importance sampling
est2 <- est
### setting higher mu's to make the events more probable
est2$est1[1] <- 4
est2$est2[1] <- 3
dmycopula <- function(Y, est) {
##############################
# This function calculate the density of the copula model at Y
# Y: the observed data with X1 and X2
##############################
x1 <- Y[,1]; x2 <- Y[,2]
u1 <- plnorm(x1, meanlog = est$est1[1], sdlog = est$est1[2])
u2 <- plnorm(x2, meanlog = est$est2[1], sdlog = est$est2[2])
dlnorm(x1, est$est1[1], est$est1[2]) *
dlnorm(x2, est$est1[1], est$est2[2]) *
dCopula(cbind(u1, u2), joeCopula(est$est3))
}
simulated_data2 <- rmycopula(k*B, est2$est1[1], est2$est1[2],
est2$est2[1], est2$est2[2], est2$est3)
V2 <- c()
for (i in 1:B){
Y <- simulated_data2[(k*(i-1)+1):(k*i),] # get Y for dmycopula
total_claim <- rowSums(Y)
### importance sampling
density_div <- dmycopula(Y, est) / dmycopula(Y, est2)
V_new <- sapply(seq(100,200,10), function(t) sum(total_claim[total_claim > t]*
density_div[total_claim > t]))
V2 <- rbind(V2,V_new)
}
View(estimate)
Vt2 <- colMeans(V2) # mean
Vt_sd2 <- apply(V, 2, sd) #sd
Vt_sd2 <- apply(V2, 2, sd)
save(Vt2, Vt_sd2, file = 'Vt2.RData')
rm(V2, simulated_data2)
results2 <- cbind(Pt, Vt2, Pt < Vt2)
results2 <- as.data.frame(results2)
names(results2) <- c('P(t)', 'V(t)', 'P(t) < V(t)')
rownames(results2) <- seq(100,200,10)
stargazer(results2, title="P(t) and V(t) based on importance sampling", header=T)
plot(seq(100,200,10), Vt2, type='b')
lines(seq(100,200,10), Pt, type='b', col='red')
plot(seq(100,200,10), Vt2, xlab ='t', ylab ='P/V', type='b')
lines(seq(100,200,10), Pt, type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
results2
Vt_sd2
Vt_sd
#### Empirical bootstrap algorithm
B <- 1000 # number of bootstrap runs
set.seed(1000)
Vt_boot <- t(sapply(1:B, function(b){
### draw samples from the observed data; using empirical bootstrapping
data_boot <- data[sample(1:length(data$ID), replace = TRUE),]
x1_boot <- data_boot[,1]; x2_boot <- data_boot[,2]
### using the above-mentioned estimate function to get estimated parameters
est_boot <- estimate(x1_boot,x2_boot)
### create est2 for importance sampling
est2_boot <- est_boot
est2_boot$est1[1] <- est2_boot$est1[1]+1
est2_boot$est2[1] <- est2_boot$est1[1]+0.1
V <- c()
### 1000 bootstrapping simulations using importance sampling
for (i in 1:10^5){
Y <- rmycopula(length(data$ID), est2$est1[1], est2$est1[2],
est2$est2[1], est2$est2[2], est2$est3)
total_claim <- rowSums(Y)
density_div <- dmycopula(Y, est) / dmycopula(Y, est2)
V_new <- sapply(seq(100,200,10), function(t) sum(total_claim[total_claim > t]*
density_div[total_claim > t]))
V <- rbind(V,V_new)
}
return(t(colMeans(V)))
}))
#### Empirical bootstrap algorithm
B <- 1000 # number of bootstrap runs
set.seed(1000)
Vt_boot <- t(sapply(1:B, function(b){
### draw samples from the observed data; using empirical bootstrapping
data_boot <- data[sample(1:length(data$ID), replace = TRUE),]
x1_boot <- data_boot[,1]; x2_boot <- data_boot[,2]
### using the above-mentioned estimate function to get estimated parameters
est_boot <- estimate(x1_boot,x2_boot)
### create est2 for importance sampling
est2_boot <- est_boot
est2_boot$est1[1] <- est2_boot$est1[1]+1
est2_boot$est2[1] <- est2_boot$est1[1]+0.1
V3 <- c()
### 1000 bootstrapping simulations using importance sampling
for (i in 1:10^5){
Y <- rmycopula(length(data$ID), est2$est1[1], est2$est1[2],
est2$est2[1], est2$est2[2], est2$est3)
total_claim <- rowSums(Y)
density_div <- dmycopula(Y, est) / dmycopula(Y, est2)
V_new <- sapply(seq(100,200,10), function(t) sum(total_claim[total_claim > t]*
density_div[total_claim > t]))
V3 <- rbind(V3,V_new)
}
return(t(colMeans(V3)))
}))
rm(simulated_data)
#### Empirical bootstrap algorithm
B <- 2#1000 # number of bootstrap runs
set.seed(1000)
system.time(
Vt_boot <- t(sapply(1:B, function(b){
### draw samples from the observed data; using empirical bootstrapping
data_boot <- data[sample(1:length(data$ID), replace = TRUE),]
x1_boot <- data_boot[,1]; x2_boot <- data_boot[,2]
### using the above-mentioned estimate function to get estimated parameters
est_boot <- estimate(x1_boot,x2_boot)
### create est2 for importance sampling
est2_boot <- est_boot
est2_boot$est1[1] <- est2_boot$est1[1]+1
est2_boot$est2[1] <- est2_boot$est1[1]+0.1
V3 <- c()
### 1000 bootstrapping simulations using importance sampling
for (i in 1:10^5){
Y <- rmycopula(length(data$ID), est2$est1[1], est2$est1[2],
est2$est2[1], est2$est2[2], est2$est3)
total_claim <- rowSums(Y)
density_div <- dmycopula(Y, est) / dmycopula(Y, est2)
V_new <- sapply(seq(100,200,10), function(t) sum(total_claim[total_claim > t]*
density_div[total_claim > t]))
V3 <- rbind(V3,V_new)
}
return(t(colMeans(V3)))
})))
3482/60
View(Vt_boot)
k
knitr::opts_chunk$set(cache=TRUE,
message=FALSE, warning=FALSE,
fig.path='figs/',
cache.path = '_cache/',
fig.process = function(x) {
x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
if (file.rename(x, x2)) x2 else x
})
library(copula)
library(WVPlots)
library(gridExtra)
library(tidyverse)
library(stargazer)
options(digits.secs = 3)
load('fit_n_times.RData')
### plot time
plot(time, type ='b')
### plot RMSE
RMSE <- as.data.frame(RMSE)
names(RMSE) <- c('mu1', 'sigma1', 'mu2', 'sigma2', 'theta')
plot(NULL, xlab = 'number_of_runs', ylab = 'RMSE',
xlim=c(0, 10^3), ylim=c(min(RMSE), max(RMSE)))
number_of_runs <- c(2,5,10) * 100
lines(number_of_runs, type ='b', RMSE$mu1, col='red')
lines(number_of_runs, type ='b', RMSE$sigma1, col='orange')
lines(number_of_runs, type ='b', RMSE$mu2, col='black')
lines(number_of_runs, type ='b', RMSE$sigma2, col='blue')
lines(number_of_runs, type ='b', RMSE$theta, col='green')
legend( x = 'topright', legend = names(RMSE), pch=1,
col = c('red', 'orange', 'black', 'blue', 'green'))
B <- 10^5 # number of simulation runs
### simulated B data points to save time
simulated_data <- rmycopula(B, est$est1[1], est$est1[2], est$est2[1], est$est2[2], est$est3)
total_claim <- rowSums(simulated_data) # x1 + x2
total_claim <- matrix(total_claim, nrow=k)
V <- sapply(seq(100,200,10), function(t)
{apply(total_claim, 2, function(x) mean(x[x > t]))})
V[is.na(V)] <- 0 # replace NA with zeros
Vt <- colMeans(V) # mean for each client
Vt_sd <- apply(V, 2, sd) # sd
log(Vt2 )
plot(log(Vt2 ))
Vt2
Vt
knitr::opts_chunk$set(cache=TRUE,
message=FALSE, warning=FALSE,
fig.path='figs/',
cache.path = '_cache/',
fig.process = function(x) {
x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
if (file.rename(x, x2)) x2 else x
})
library(copula)
library(WVPlots)
library(gridExtra)
library(tidyverse)
library(knitr)
tinytex::install_tinytex()
knitr::opts_chunk$set(cache=TRUE,
message=FALSE, warning=FALSE,
fig.path='figs/',
cache.path = '_cache/',
fig.process = function(x) {
x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
if (file.rename(x, x2)) x2 else x
})
library(copula)
library(WVPlots)
library(gridExtra)
library(tidyverse)
library(knitr)
#tinytex::install_tinytex()
options(digits.secs = 3)
knitr::opts_chunk$set(cache=TRUE,
message=FALSE, warning=FALSE,
fig.path='figs/',
cache.path = '_cache/',
fig.process = function(x) {
x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
if (file.rename(x, x2)) x2 else x
})
library(copula)
library(WVPlots)
library(gridExtra)
library(tidyverse)
library(knitr)
tinytex::install_tinytex()
options(digits.secs = 3)
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
mean_boot <- apply(V3, 2, mean)
load('Vt_boot.RData')
### construct the confident intervals
mean_boot <- apply(V3, 2, mean)
se_boot <- apply(V3, 2, sd) # Bootstrap se's of the coefficients
### calculate 80% confidence intervals for V(t)
CI_low <- mean_boot + se_boot * qnorm(0.1)
CI_low[CI_low < 0] <- 0
CI_up  <- mean_boot + se_boot * qnorm(0.9)
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(seq(100,200,10), CI_low, lty=2)
lines(seq(100,200,10), CI_up, lty=2)
lines(seq(100,200,10), Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
arrows(t, L, t, U, length=0.05, angle=90, code=3)
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(seq(100,200,10), CI_low, lty=2)
lines(seq(100,200,10), CI_up, lty=2)
lines(seq(100,200,10), Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
arrows(seq(100,200,10), CI_low, seq(100,200,10), CI_up, length=0.05, angle=90, code=3)
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(seq(100,200,10), Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
arrows(seq(100,200,10), CI_low, seq(100,200,10), CI_up, length=0.05, angle=90, code=3)
quantile(V3)
mean_boot
V3
apply(V3, 2, quantile)
apply(V3, 2, quantile(probs = c(0.1,0.9))
)
apply(V3, 2, function(x) quantile(x, probs = c(0.1,0.9)))
apply(V3, 2, function(x) quantile(x, probs = c(0.1,0.9)))[1,]
apply(V3, 2, function(x) quantile(x, probs = c(0.1,0.9)))[2,]
### construct the confident intervals
mean_boot <- apply(V3, 2, mean)
quantile_boot <- apply(V3, 2, function(x) quantile(x, probs = c(0.1,0.9))) # quantile
### calculate 80% confidence intervals for V(t)
CI_low <- quantile_boot[1,]
CI_up  <- quantile_boot[2,]
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(seq(100,200,10), Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
arrows(seq(100,200,10), CI_low, seq(100,200,10), CI_up, length=0.05, angle=90, code=3)
CI_low
CI_up
CI_low  - CI_up
?arrows
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(seq(100,200,10), Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
arrows(seq(100,200,10), CI_low, seq(100,200,10), CI_up, length=0.05, angle=90, code=4)
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(seq(100,200,10), Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
arrows(seq(100,200,10), CI_low, seq(100,200,10), CI_up, length=0.05, angle=90, code=3)
plot(seq(100,200,10), mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(seq(100,200,10), Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
arrows(seq(100,200,10), CI_low, seq(100,200,10), CI_up, length=0.005, angle=90, code=3)
t <- seq(100,200,10)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,CI_low),c(t,CI_up),col="skyblue")
arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend( x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,CI_low),c(t,CI_up),col="skyblue")
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,CI_low),c(t,CI_up),col=gray(0.8))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,t),c(CI_low,CI_up),col=gray(0.8))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
rev(t)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t),c(CI_low,CI_up),col=gray(0.8))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,CI_up),col=gray(0.8))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=gray(0.3))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col='gray', alpha=0.1)
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(1, 0, 0,0.5))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(100, 100, 100,0.2))
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', ylim=c(0,0.05), type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
#arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', ylim=c(0,0.05), type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', ylim=c(0,0.05), type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', ylim=c(0,0.05), type='l')
lines(t, Pt,type='l', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
plot(t, mean_boot, xlab ='threshold(t)', ylab ='P/V', ylim=c(0,0.05), type='b')
lines(t, Pt,type='b', col='red')
legend(x = 'topright', legend = c('Vt','Pt'), pch=1,
col = c('black', 'red'))
polygon(c(t,rev(t)),c(CI_low,rev(CI_up)),col=rgb(.5, .5, .5,0.2))
arrows(t, CI_low, t, CI_up, length=0.05, angle=90, code=3)
