\documentclass[11pt,]{article}
\usepackage[left=1in,top=1in,right=1in,bottom=1in]{geometry}
\newcommand*{\authorfont}{\fontfamily{phv}\selectfont}
\usepackage[]{mathpazo}


  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}




\usepackage{abstract}
\renewcommand{\abstractname}{}    % clear the title
\renewcommand{\absnamepos}{empty} % originally center

\renewenvironment{abstract}
 {{%
    \setlength{\leftmargin}{0mm}
    \setlength{\rightmargin}{\leftmargin}%
  }%
  \relax}
 {\endlist}

\makeatletter
\def\@maketitle{%
  \newpage
%  \null
%  \vskip 2em%
%  \begin{center}%
  \let \footnote \thanks
    {\fontsize{18}{20}\selectfont\raggedright  \setlength{\parindent}{0pt} \@title \par}%
}
%\fi
\makeatother




\setcounter{secnumdepth}{0}

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}

\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}


\title{End-term project: Advanced Statistical Computing 2020  }



\author{\Large Yizhen Dai\vspace{0.05in} \newline\normalsize\emph{s2395479}  }


\date{}

\usepackage{titlesec}

\titleformat*{\section}{\normalsize\bfseries}
\titleformat*{\subsection}{\normalsize\itshape}
\titleformat*{\subsubsection}{\normalsize\itshape}
\titleformat*{\paragraph}{\normalsize\itshape}
\titleformat*{\subparagraph}{\normalsize\itshape}


\usepackage{natbib}
\bibliographystyle{apsr}
\usepackage[strings]{underscore} % protect underscores in most circumstances



\newtheorem{hypothesis}{Hypothesis}
\usepackage{setspace}


% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage{hyperref}

% move the hyperref stuff down here, after header-includes, to allow for - \usepackage{hyperref}

\makeatletter
\@ifpackageloaded{hyperref}{}{%
\ifxetex
  \PassOptionsToPackage{hyphens}{url}\usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \PassOptionsToPackage{hyphens}{url}\usepackage[draft,unicode=true]{hyperref}
\fi
}

\@ifpackageloaded{color}{
    \PassOptionsToPackage{usenames,dvipsnames}{color}
}{%
    \usepackage[usenames,dvipsnames]{color}
}
\makeatother
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Yizhen Dai (s2395479)},
             pdfkeywords = {Advanced Statistical Computating, Final Project, Simulation},  
            pdftitle={End-term project: Advanced Statistical Computing 2020},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

% Add an option for endnotes. -----


% add tightlist ----------
\providecommand{\tightlist}{%
\setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% add some other packages ----------

% \usepackage{multicol}
% This should regulate where figures float
% See: https://tex.stackexchange.com/questions/2275/keeping-tables-figures-close-to-where-they-are-mentioned
\usepackage[section]{placeins}


\begin{document}
	
% \pagenumbering{arabic}% resets `page` counter to 1 
%
% \maketitle

{% \usefont{T1}{pnc}{m}{n}
\setlength{\parindent}{0pt}
\thispagestyle{plain}
{\fontsize{18}{20}\selectfont\raggedright 
\maketitle  % title \par  

}

{
   \vskip 13.5pt\relax \normalsize\fontsize{11}{12} 
\textbf{\authorfont Yizhen Dai} \hskip 15pt \emph{\small s2395479}   

}

}








\begin{abstract}

    \hbox{\vrule height .2pt width 39.14pc}

    \vskip 8.5pt % \small 

\noindent This report is the result of the efforts for the final exam/project of
Advanced Statistical Computating. The goal of this project is to analyze
the cost and the benefit of a re-insruance policy through simulation.


\vskip 8.5pt \noindent \emph{Keywords}: Advanced Statistical Computating, Final Project, Simulation \par

    \hbox{\vrule height .2pt width 39.14pc}



\end{abstract}


\vskip -8.5pt


 % removetitleabstract

\noindent  

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

\hypertarget{the-goal}{%
\subsection{The goal}\label{the-goal}}

This project aims at solving a modeling problem faced by an insurance
company - ANV. Two of ANV business lines,
\href{https://en.wikipedia.org/wiki/Professional_liability_insurance}{Professional
liability insurance} (PLI) and
\href{https://en.wikipedia.org/wiki/Workers\%27_compensation}{Workers'
compensation} (WC), were affected by a huge claim from one client during
the last year. Therefore, ANV comes to a reinsurance company for an
insurance policy. To put the problem in a mathematical format, we define
the following notation: * \(X_1\): the loss incurred for PLI from ANV
clients (in million euros); * \(X_2\): the loss incurred for WC from ANV
clients (in million euros); * \(t\): the threshold set by the
reinsurance company (in million euros). For some threshold
\(t = 100,110,…,200\), if the total loss incurred for PLI and WC from a
certain client exceeds \(t\), ANV pays the claim themselves; Otherwise,
the reinsurance company pays the claim; * \(V(t)\): the expected
over-threshold claims, which is equal to \(E[(X_1+X_2)1(X_1+X_2>t)]\); *
\(P(t)\): the price that reinsurance company asks. \(P(t)\) depends on
the threshold \(t\) as \(P(t)=40000 * e^{-t/7}\).

Our goal is to determine if ANV should buy such policy from the
reinsurance company. Of course, the policy is only reasonable if the
expected over-threshold claim exceeds the price: \(V(t) > P(t)\). The
data available is the loss incurred for PLI and WC for all the clients
of ANV during last year. With limited data available, we use statistical
modeling to approximate \(V(t)\) and therefore determine if
\(V(t) > P(t)\).

\hypertarget{models}{%
\subsection{Models}\label{models}}

\(X_1\) and \(X_2\) are positively correlated. The correlation between
\(X_1\) and \(X_2\) is 0.528. The linear regression line (in red) and
the \emph{LOWESS} smoother line (in blue) is shown below in Figure 1.

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-2.pdf}
\caption{The relationship between X1 and X2}
\end{figure}

In order to reflect the dependence in the data, we cannot simulate
\(X_1\) and \(X_2\) separately. We use a Copula model to model the joint
density \(f_{X_{1}, X_{2}}\).

\[
f_{X_{1}, X_{2}}\left(x_{1}, x_{2}\right)=f_{X_{1}}\left(x_{1}\right) f_{X_{2}}\left(x_{2}\right) c\left(u_1,u_2\right)
\]

where
\(u_1 = F_{X_{1}}\left(x_{1}\right),u2= F_{X_{2}}\left(x_{2}\right)\),
which are the marginal functions of \(f_{X_{1}}\) and \(f_{X_{2}}\);
\(c\left(u_{1}, u_{2}\right)\) is the joint integral transforms
\(U_{1}=F_{X_{1}}\left(X_{1}\right)\) and
\(U_{2}=F_{X_{2}}\left(X_{2}\right)\).

Preliminary experiments suggested the following parametric models:

\(f_{X_{1}}\left(\cdot ; \mu_{1}, \sigma_{1}\right) \sim \textrm{Lognormal} \left(\mu_{1}, \sigma_{1}\right), \mu_{1} \in \mathbb{R}, \sigma_{1}>0\)

\(f_{X_{2}}\left(\cdot ; \mu_{2}, \sigma_{2}\right) \sim \textrm{Lognormal} \left(\mu_{2}, \sigma_{2}\right), \mu_{2} \in \mathbb{R}, \sigma_{2}>0\)

\(c(\cdot ; \theta) \sim \textrm{Joe}(\theta), \theta \geq 1\)

where a Lognormal distribution is for a random variable whose logarithm
is normally distributed; a Joe distribution is one of the most prominent
bivariate Archimedean copulas in Copula models.

\hypertarget{methodolgy}{%
\section{Methodolgy}\label{methodolgy}}

\hypertarget{parameter-estimates}{%
\subsection{Parameter Estimates}\label{parameter-estimates}}

Based on the models, we have a total of five parameters to be estimated
from the data: \(\mu_{1},\sigma_{1},\mu_{2},\sigma_{2}\theta\). The
maximum likelihood estimation is used to estimate these parameters.

First, we estimate \(\mu_{1},\sigma_{1},\mu_{2},\sigma_{2}\) by finding
the values that can maximize the sum of log density of the observed data
so the data is most probable under our model assumption
\(f_{X_{1}},f_{X_{2}}\). To speed up the optimization, we can use the
sample mean and sample standard deviation of the observed data on the
log scale.

Afterwards, we estimate \(\theta\) using the probability integral
transforms of the observed data. Such transforms are not observed get
pseudo-observations by plugging in the estimated
\(\mu_{1},\sigma_{1},\mu_{2},\sigma_{2}\). It might work if our
estimated parameters are close to the true parameters.

The codes for parameter estimates are shown below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get_theta <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2, est1, est2) \{}
    \CommentTok{### This function estimate theta using pseudo-observations}
    
    \CommentTok{### x1 and x2 are the observed data}
    
    \CommentTok{### est1 and est2 are the estimated parameters of lognormal distribution}
    
    
    \CommentTok{### get u1 and u2 based on the estimated mu and sigma}
\NormalTok{    u1 <-}\StringTok{ }\KeywordTok{plnorm}\NormalTok{(x1, }\DataTypeTok{meanlog =}\NormalTok{ est1[}\DecValTok{1}\NormalTok{], }\DataTypeTok{sdlog =}\NormalTok{ est1[}\DecValTok{2}\NormalTok{])}
\NormalTok{    u2 <-}\StringTok{ }\KeywordTok{plnorm}\NormalTok{(x2, }\DataTypeTok{meanlog =}\NormalTok{ est2[}\DecValTok{1}\NormalTok{], }\DataTypeTok{sdlog =}\NormalTok{ est2[}\DecValTok{2}\NormalTok{])}
    \CommentTok{### using Joe(theta)-density; evaluated at u; u is a (n x 2) matrix}
\NormalTok{    g3 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(theta) \{}
        \OperatorTok{-}\KeywordTok{sum}\NormalTok{(}\KeywordTok{dCopula}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(u1, u2), }\KeywordTok{joeCopula}\NormalTok{(theta), }\DataTypeTok{log =}\NormalTok{ T), }\DataTypeTok{na.rm =}\NormalTok{ T)}
\NormalTok{    \}}
    \CommentTok{### minimize the negative log likelihood function for the copula function}
    \KeywordTok{nlminb}\NormalTok{(}\DecValTok{2}\NormalTok{, g3, }\DataTypeTok{lower =} \DecValTok{1} \OperatorTok{+}\StringTok{ }\DecValTok{10}\OperatorTok{^-}\DecValTok{8}\NormalTok{, }\DataTypeTok{upper =} \OtherTok{Inf}\NormalTok{)}\OperatorTok{$}\NormalTok{par}
\NormalTok{\}}


\NormalTok{estimate <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x1, x2) \{}
    \CommentTok{### This function estimate the five parameters in our Copula model}
    
    \CommentTok{### x1 and x2 are the observed data}
    
\NormalTok{    meanlog <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\KeywordTok{log}\NormalTok{(x1), }\KeywordTok{log}\NormalTok{(x2)), mean)}
\NormalTok{    sdlog <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\KeywordTok{log}\NormalTok{(x1), }\KeywordTok{log}\NormalTok{(x2)), sd)}
    
    \CommentTok{### negative log likelihood function to be minimized}
\NormalTok{    g1 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(beta) \{}
        \OperatorTok{-}\KeywordTok{sum}\NormalTok{(}\KeywordTok{dlnorm}\NormalTok{(x1, }\DataTypeTok{meanlog =}\NormalTok{ beta[}\DecValTok{1}\NormalTok{], }\DataTypeTok{sdlog =}\NormalTok{ beta[}\DecValTok{2}\NormalTok{], }\DataTypeTok{log =}\NormalTok{ T), }\DataTypeTok{na.rm =}\NormalTok{ T)}
\NormalTok{    \}}
\NormalTok{    g2 <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(beta) \{}
        \OperatorTok{-}\KeywordTok{sum}\NormalTok{(}\KeywordTok{dlnorm}\NormalTok{(x2, }\DataTypeTok{meanlog =}\NormalTok{ beta[}\DecValTok{1}\NormalTok{], }\DataTypeTok{sdlog =}\NormalTok{ beta[}\DecValTok{2}\NormalTok{], }\DataTypeTok{log =}\NormalTok{ T), }\DataTypeTok{na.rm =}\NormalTok{ T)}
\NormalTok{    \}}
    
    \CommentTok{### Compute estimates for x1 by maximum likelihood method}
\NormalTok{    est1 <-}\StringTok{ }\KeywordTok{nlminb}\NormalTok{(}\KeywordTok{c}\NormalTok{(meanlog[}\DecValTok{1}\NormalTok{], sdlog[}\DecValTok{1}\NormalTok{]), g1, }\DataTypeTok{lower =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\OtherTok{Inf}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DataTypeTok{upper =} \OtherTok{Inf}\NormalTok{)}\OperatorTok{$}\NormalTok{par}
    \KeywordTok{names}\NormalTok{(est1) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"mu1"}\NormalTok{, }\StringTok{"sigma1"}\NormalTok{)}
    
    \CommentTok{### Compute estimates for x2 by maximum likelihood method}
\NormalTok{    est2 <-}\StringTok{ }\KeywordTok{nlminb}\NormalTok{(}\KeywordTok{c}\NormalTok{(meanlog[}\DecValTok{2}\NormalTok{], sdlog[}\DecValTok{2}\NormalTok{]), g2, }\DataTypeTok{lower =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\OtherTok{Inf}\NormalTok{, }\DecValTok{0}\NormalTok{), }\DataTypeTok{upper =} \OtherTok{Inf}\NormalTok{)}\OperatorTok{$}\NormalTok{par}
    \KeywordTok{names}\NormalTok{(est2) <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"mu2"}\NormalTok{, }\StringTok{"sigma2"}\NormalTok{)}
    
    \CommentTok{### Estimate the parameters of a Joe copula model for (U1,U2).}
\NormalTok{    est3 <-}\StringTok{ }\KeywordTok{get_theta}\NormalTok{(x1, x2, est1, est2)}
    
    \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{est1 =}\NormalTok{ est1, }\DataTypeTok{est2 =}\NormalTok{ est2, }\DataTypeTok{est3 =}\NormalTok{ est3))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The estimated parameters are
\(\hat{\mu_{1}}= 1.982,\hat{\sigma_{1}}=0.513,\hat{\mu_{2}}=2.997,\hat{\sigma_{2}}=0.311,\hat{\theta}=1.608\).

\hypertarget{simulated-data}{%
\subsection{Simulated data}\label{simulated-data}}

We get the parameter estimates, then we can simulate enough data to get
the average cost \(V(t)\) over the years.

To generate enough data, we need a function that simulates from the
joint model for \((X_1,X_2)\) for a given set of parameters
\((\mu_{1}, \sigma_{1},\mu_{2},\sigma_{2},\theta)\). The function is
shown below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rmycopula <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, mu1, sd1, mu2, sd2, theta) \{}
    \CommentTok{### This function simulates n samples from a Joe copula with estimated}
    \CommentTok{### parameters}
    
    \CommentTok{### use rCopula(n, joeCopula(theta)) to simulate u1 and u2}
\NormalTok{    u <-}\StringTok{ }\KeywordTok{rCopula}\NormalTok{(n, }\KeywordTok{joeCopula}\NormalTok{(theta))  }\CommentTok{# u is a (n x 2) matrix}
\NormalTok{    x1 <-}\StringTok{ }\KeywordTok{qlnorm}\NormalTok{(u[, }\DecValTok{1}\NormalTok{], mu1, sd1)}
\NormalTok{    x2 <-}\StringTok{ }\KeywordTok{qlnorm}\NormalTok{(u[, }\DecValTok{2}\NormalTok{], mu2, sd2)}
    \KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(x1, x2))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

To evaluate our estimated model, we can compare the simulated data using
the above function with the observed data. They are shown in Figure 2
and Figure 3.

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-6.pdf}
\caption{Observed Data}
\end{figure}

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-7.pdf}
\caption{Simulated Data}
\end{figure}

We can see the marginal and joint distributions of observed data and
simulated data are similar, which is a good sign of our implementation.

We can also check change in data distributions when we tune the
parameters using our simulation function. Currently
\(\hat{\mu_{1}},= 1.982, \hat{\sigma_{1}}=0.513,\hat{\mu_{2}}=2.997,\hat{\sigma_{2}}=0.311,\hat{\theta}=1.608\).

First, we increase \(\theta\) to 4. The results are shown in Figure 4.
We can see with a bigger theta, the data are more correlated with
smaller deviation from the linear regression line.

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-8.pdf}
\caption{theta = 4}
\end{figure}

Next, we check the distribution with bigger \(\mu_1=3, \mu_2=4\). The
results are shown in Figure 5. We can see when we increase
\(\mu_1,\mu_2\), the center of the contour also shifts in the same
direction.

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-9.pdf}
\caption{mu1 = 3, mu2 = 4}
\end{figure}

Next, we check the distribution with bigger standard deviation of
Lognormal distribution: \(\sigma_1 =\sigma_2 = 0.8\). The results are
shown in Figure 6. We can see that the data is more dispersed, which is
same as expected. We can also observe that a small change in
\(\sigma_1, \sigma_2\) has a big influence on the extreme values. This
is partly because the \(\sigma\) is on the log scale.

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-10.pdf}
\caption{sigma1 = sigma2 = 0.8}
\end{figure}

\hypertarget{simulation-study}{%
\section{Simulation Study}\label{simulation-study}}

\hypertarget{acuracy-evaluation}{%
\subsection{Acuracy evaluation}\label{acuracy-evaluation}}

To evaluate how accurate our parameter estimation can be, we conduct a
simulation study assuming the following values for true parameters:
\(\mu_1=1,\sigma_1=2,\mu_2=3,\sigma_2=0.5,\theta=2\).

We compute the RMSE for 100 simulation runs of 200,500 and 1000 data
points. The codes for accuracy analysis is shown below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_n_times <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n)\{}
  \CommentTok{### This function estimates the parameters for 100 times and returns the RMSE}
  
  \CommentTok{### n: the number of data points in each simulation run}
  
  \CommentTok{### simulate}
\NormalTok{  sim_data <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{100}\NormalTok{,}\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{rmycopula}\NormalTok{(n, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{  results <-}\StringTok{ }\KeywordTok{c}\NormalTok{()}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{100}\NormalTok{)\{}
\NormalTok{    results <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(results, }
                     \KeywordTok{unlist}\NormalTok{(}\KeywordTok{estimate}\NormalTok{(sim_data[[i]]}\OperatorTok{$}\NormalTok{x1, sim_data[[i]]}\OperatorTok{$}\NormalTok{x2)))}
\NormalTok{  \}}
  \CommentTok{### calculate RMSE}
\NormalTok{  (results }\OperatorTok{-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\DecValTok{2}\NormalTok{))}\OperatorTok{^}\DecValTok{2} \OperatorTok{%>%}\StringTok{   }\CommentTok{# estimated minus true values}
\StringTok{    }\KeywordTok{rowMeans}\NormalTok{(.) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{sqrt}\NormalTok{(.)}
\NormalTok{\}}

\CommentTok{### initiate time and RMSE}
\NormalTok{time <-}\StringTok{ }\KeywordTok{numeric}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\NormalTok{RMSE <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{) }

\CommentTok{### conduct simulation for n = 200,500 and 1000}
\NormalTok{i <-}\StringTok{ }\DecValTok{1}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{) }\OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{) \{}
\NormalTok{  time[i] <-}\StringTok{ }\KeywordTok{system.time}\NormalTok{(RMSE[i,] <-}\StringTok{ }\KeywordTok{fit_n_times}\NormalTok{(n))}\OperatorTok{/}\DecValTok{100} \CommentTok{# average computing time}
\NormalTok{  i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{\}}

\CommentTok{### update format for plotting}
\NormalTok{time <-}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{number_of_runs=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{10}\NormalTok{) }\OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{, }\DataTypeTok{time=}\NormalTok{time)}
\end{Highlighting}
\end{Shaded}

The average computing time and RMSE are shown in Figure 7 and Figure 8.

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-14.pdf}
\caption{Average computing time vs number of runs}
\end{figure}

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-15.pdf}
\caption{RMSE vs number of runs}
\end{figure}

We can see that required computation time increase linearly with the
number of runs.

RMSE gets smaller with more simulation runs. \(\theta\) is the hardest
parameter to estimate with largest RMSE. \(\mu_1, \sigma_1\) have higher
RMSE than \(\mu_2, \sigma_2\) separately. This is probably due to a
lower standard deviation for \(f_{X_2}\) (0.5 compared to 2 on the log
scale). The distribution for \(f_{X_1}\) is more dispersed, leading to a
larger RMSE for \(\mu_1, \sigma_1\).

\hypertarget{working-on-the-real-data-vt}{%
\subsection{Working on the real data:
V(t)}\label{working-on-the-real-data-vt}}

Having a feeling of the simulation models, we fit all the five
parameters to the observed data. We compute the expected payout of the
reinsurance \(V(t)\) using parametric Monte Carlo simulation (based on
the estimated parameters). We use \(10^5\) Monte Carlo samples and
calculate expected \(V(t), t=100,110,…,200\), as the average over the
simulation runs.The codes are shown below

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B <-}\StringTok{ }\DecValTok{10}\OperatorTok{^}\DecValTok{5}  \CommentTok{# number of simulation runs}

\CommentTok{### simulated B data points to save time}
\NormalTok{simulated_data <-}\StringTok{ }\KeywordTok{rmycopula}\NormalTok{(B, est}\OperatorTok{$}\NormalTok{est1[}\DecValTok{1}\NormalTok{], est}\OperatorTok{$}\NormalTok{est1[}\DecValTok{2}\NormalTok{], est}\OperatorTok{$}\NormalTok{est2[}\DecValTok{1}\NormalTok{], est}\OperatorTok{$}\NormalTok{est2[}\DecValTok{2}\NormalTok{], }
\NormalTok{    est}\OperatorTok{$}\NormalTok{est3)}
\NormalTok{total_claim <-}\StringTok{ }\KeywordTok{rowSums}\NormalTok{(simulated_data)  }\CommentTok{# x1 + x2}

\CommentTok{### replace claims <= t with zeros}
\NormalTok{V <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{10}\NormalTok{), }\ControlFlowTok{function}\NormalTok{(t) }\KeywordTok{c}\NormalTok{(total_claim[total_claim }\OperatorTok{>}\StringTok{ }\NormalTok{t], }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }
    \KeywordTok{sum}\NormalTok{(total_claim }\OperatorTok{<=}\StringTok{ }\NormalTok{t))))}

\NormalTok{Vt <-}\StringTok{ }\KeywordTok{colMeans}\NormalTok{(V)  }\CommentTok{# mean for each client}
\NormalTok{Vt_sd <-}\StringTok{ }\KeywordTok{apply}\NormalTok{(V, }\DecValTok{2}\NormalTok{, sd)  }\CommentTok{# sd}
\end{Highlighting}
\end{Shaded}

The plot of \(V(t)\) for \(t=100,110,…,200\) based on \(10^5\) Monte
Carlo samples is shown in Figure 9.

\begin{longtable}[]{@{}lrrrr@{}}
\toprule
& P(t) & V(t) & Std for V(t) & P(t) \textless{} V(t)\tabularnewline
\midrule
\endhead
100 & 0.0249950 & 0.0305661 & 1.8318015 & 1\tabularnewline
110 & 0.0059901 & 0.0108184 & 1.1414797 & 1\tabularnewline
120 & 0.0014355 & 0.0074188 & 0.9579313 & 1\tabularnewline
130 & 0.0003440 & 0.0000000 & 0.0000000 & 0\tabularnewline
140 & 0.0000824 & 0.0000000 & 0.0000000 & 0\tabularnewline
150 & 0.0000198 & 0.0000000 & 0.0000000 & 0\tabularnewline
160 & 0.0000047 & 0.0000000 & 0.0000000 & 0\tabularnewline
170 & 0.0000011 & 0.0000000 & 0.0000000 & 0\tabularnewline
180 & 0.0000003 & 0.0000000 & 0.0000000 & 0\tabularnewline
190 & 0.0000001 & 0.0000000 & 0.0000000 & 0\tabularnewline
200 & 0.0000000 & 0.0000000 & 0.0000000 & 0\tabularnewline
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-21.pdf}
\caption{P(t) vs t}
\end{figure}

Based on the results, buying the reinsurance policy seems a good idea
when \(t\leq120\) since the policy price (\(P(t)\))is smaller than the
potential cost of not buying the policy (\(V(t)\)). However, the
standard deviation is high for \(V(t)\). This is because the claim
exceeding \(t\) is a highly improbable event.

\hypertarget{importance-sampling}{%
\subsection{Importance sampling}\label{importance-sampling}}

To handle the highly improbable events, we use importance sampling. The
codes are shown below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{### new parameters est2 for importance sampling}
\NormalTok{est2 <-}\StringTok{ }\NormalTok{est}
\CommentTok{### setting higher mu's to make the events more probable}
\NormalTok{est2}\OperatorTok{$}\NormalTok{est1[}\DecValTok{1}\NormalTok{] <-}\StringTok{ }\NormalTok{est2}\OperatorTok{$}\NormalTok{est1[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\FloatTok{0.5}
\NormalTok{est2}\OperatorTok{$}\NormalTok{est2[}\DecValTok{1}\NormalTok{] <-}\StringTok{ }\NormalTok{est2}\OperatorTok{$}\NormalTok{est2[}\DecValTok{1}\NormalTok{] }\OperatorTok{+}\StringTok{ }\FloatTok{0.5}


\NormalTok{dmycopula <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(Y, est) \{}
    \CommentTok{### This function calculate the density of the copula model at Y Y: the}
    \CommentTok{### observed data with X1 and X2}
\NormalTok{    x1 <-}\StringTok{ }\NormalTok{Y[, }\DecValTok{1}\NormalTok{]}
\NormalTok{    x2 <-}\StringTok{ }\NormalTok{Y[, }\DecValTok{2}\NormalTok{]}
\NormalTok{    u1 <-}\StringTok{ }\KeywordTok{plnorm}\NormalTok{(x1, }\DataTypeTok{meanlog =}\NormalTok{ est}\OperatorTok{$}\NormalTok{est1[}\DecValTok{1}\NormalTok{], }\DataTypeTok{sdlog =}\NormalTok{ est}\OperatorTok{$}\NormalTok{est1[}\DecValTok{2}\NormalTok{])}
\NormalTok{    u2 <-}\StringTok{ }\KeywordTok{plnorm}\NormalTok{(x2, }\DataTypeTok{meanlog =}\NormalTok{ est}\OperatorTok{$}\NormalTok{est2[}\DecValTok{1}\NormalTok{], }\DataTypeTok{sdlog =}\NormalTok{ est}\OperatorTok{$}\NormalTok{est2[}\DecValTok{2}\NormalTok{])}
    \KeywordTok{dlnorm}\NormalTok{(x1, est}\OperatorTok{$}\NormalTok{est1[}\DecValTok{1}\NormalTok{], est}\OperatorTok{$}\NormalTok{est1[}\DecValTok{2}\NormalTok{]) }\OperatorTok{*}\StringTok{ }\KeywordTok{dlnorm}\NormalTok{(x2, est}\OperatorTok{$}\NormalTok{est2[}\DecValTok{1}\NormalTok{], est}\OperatorTok{$}\NormalTok{est2[}\DecValTok{2}\NormalTok{]) }\OperatorTok{*}\StringTok{ }
\StringTok{        }\KeywordTok{dCopula}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(u1, u2), }\KeywordTok{joeCopula}\NormalTok{(est}\OperatorTok{$}\NormalTok{est3))}
\NormalTok{\}}

\NormalTok{simulated_data2 <-}\StringTok{ }\KeywordTok{rmycopula}\NormalTok{(B, est2}\OperatorTok{$}\NormalTok{est1[}\DecValTok{1}\NormalTok{], est2}\OperatorTok{$}\NormalTok{est1[}\DecValTok{2}\NormalTok{], est2}\OperatorTok{$}\NormalTok{est2[}\DecValTok{1}\NormalTok{], est2}\OperatorTok{$}\NormalTok{est2[}\DecValTok{2}\NormalTok{], }
\NormalTok{    est2}\OperatorTok{$}\NormalTok{est3)}
\NormalTok{total_claim2 <-}\StringTok{ }\KeywordTok{rowSums}\NormalTok{(simulated_data2)}

\NormalTok{V2 <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{200}\NormalTok{, }\DecValTok{10}\NormalTok{), }\ControlFlowTok{function}\NormalTok{(t) \{}
\NormalTok{    ind <-}\StringTok{ }\NormalTok{(total_claim2 }\OperatorTok{>}\StringTok{ }\NormalTok{t)  }\CommentTok{# index for the data with total claim > t}
\NormalTok{    temp <-}\StringTok{ }\NormalTok{simulated_data2[ind, ]  }\CommentTok{# get Y for dmycopula}
    \CommentTok{### importance sampling}
    \KeywordTok{c}\NormalTok{(total_claim2[ind] }\OperatorTok{*}\StringTok{ }\KeywordTok{dmycopula}\NormalTok{(temp, est)}\OperatorTok{/}\KeywordTok{dmycopula}\NormalTok{(temp, est2), }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }
\NormalTok{        B }\OperatorTok{-}\StringTok{ }\KeywordTok{sum}\NormalTok{(ind)))  }\CommentTok{# replace claims <= t with zeros}
\NormalTok{\})}

\NormalTok{Vt2 <-}\StringTok{ }\KeywordTok{colMeans}\NormalTok{(V2)  }\CommentTok{# mean for each client}
\NormalTok{Vt_sd2 <-}\StringTok{ }\KeywordTok{apply}\NormalTok{(V2, }\DecValTok{2}\NormalTok{, sd)  }\CommentTok{# sd}
\end{Highlighting}
\end{Shaded}

The plot of \(V(t)\) for \(t=100,110,…,200\) based on \(10^5\) Monte
Carlo samples and importance sampling is shown in Figure 10.

\begin{longtable}[]{@{}lrrrr@{}}
\toprule
& P(t) & V(t) & Std of V(t) & P(t) \textless{} V(t)\tabularnewline
\midrule
\endhead
100 & 0.0249950 & 0.0280979 & 0.4863116 & 1\tabularnewline
110 & 0.0059901 & 0.0136015 & 0.3358949 & 1\tabularnewline
120 & 0.0014355 & 0.0058363 & 0.2110803 & 1\tabularnewline
130 & 0.0003440 & 0.0026723 & 0.1389756 & 1\tabularnewline
140 & 0.0000824 & 0.0010283 & 0.0803192 & 1\tabularnewline
150 & 0.0000198 & 0.0005796 & 0.0600486 & 1\tabularnewline
160 & 0.0000047 & 0.0001392 & 0.0230496 & 1\tabularnewline
170 & 0.0000011 & 0.0001029 & 0.0223332 & 1\tabularnewline
180 & 0.0000003 & 0.0000362 & 0.0073649 & 1\tabularnewline
190 & 0.0000001 & 0.0000231 & 0.0065468 & 1\tabularnewline
200 & 0.0000000 & 0.0000209 & 0.0065346 & 1\tabularnewline
\bottomrule
\end{longtable}

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-27.pdf}
\caption{P(t) and V(t) vs t based on importance sampling}
\end{figure}

The \(V(t)\) based on importance sampling have values when \(t>120\).
Based on the results, the company should buy the reinsurance policy
regardless of the value of \(t\).

\hypertarget{confidence-intervals}{%
\subsection{Confidence Intervals}\label{confidence-intervals}}

Since we are not sure how confident we are about our estimates, we can
to conduct bootstrapping to get confidence intervals of \(V(t)\). The
codes doing a bootstrap method (1000 times) to compute 80\% confidence
intervals for \(V(t)\) are shown below. The results are shown in Figure
11.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{### construct the confident intervals}
\NormalTok{mean_boot <-}\StringTok{ }\KeywordTok{apply}\NormalTok{(V3, }\DecValTok{2}\NormalTok{, mean)}
\NormalTok{se_boot <-}\StringTok{ }\KeywordTok{apply}\NormalTok{(V3, }\DecValTok{2}\NormalTok{, sd)  }\CommentTok{# Bootstrap se's of the coefficients}
\CommentTok{### calculate 80% confidence intervals for V(t)}
\NormalTok{CI_low <-}\StringTok{ }\NormalTok{mean_boot }\OperatorTok{+}\StringTok{ }\NormalTok{se_boot }\OperatorTok{*}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.1}\NormalTok{)}
\NormalTok{CI_low[CI_low }\OperatorTok{<}\StringTok{ }\DecValTok{0}\NormalTok{] <-}\StringTok{ }\DecValTok{0}
\NormalTok{CI_up <-}\StringTok{ }\NormalTok{mean_boot }\OperatorTok{+}\StringTok{ }\NormalTok{se_boot }\OperatorTok{*}\StringTok{ }\KeywordTok{qnorm}\NormalTok{(}\FloatTok{0.9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{figs/unnamed-chunk-32.pdf}
\caption{90\% Confidence Interval P(t) in dashed line and V(t)}
\end{figure}

\hypertarget{results}{%
\section{Results}\label{results}}

As you can see from the Figure 11, there is huge uncertainty in the
values of \(P(t)\). We cannot draw a conclusion that \(V(t)\) will be
smaller than \(P(t)\) on a 90\% confidence level.

\begin{itemize}
\tightlist
\item
  The implementation does account for Monte Carlo approximation error
  since we are doing bootstrapping.
\item
  The implementation does not account for estimation error since we are
  relying on the existing data (648 data points).
\end{itemize}





\newpage
\singlespacing 
\bibliography{master.bib}

\end{document}
